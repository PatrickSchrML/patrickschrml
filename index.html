<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Safe & Ethical AI</title>
    <style>
        body {
            margin: 0;
            font-family: "Georgia", serif;
            color: #333;
            background-color: #f8f5f0;
            line-height: 1.6;
        }
        header {
            background-color: #f8f5f0;/* brand iaseai  rgb(181, 78, 18);*/
            color: #333;/* brand iaseai white;*/
            padding: 20px;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        header h1 {
            font-size: 28px;
            margin: 0;
        }
        nav {
            display: flex;
            gap: 20px;
        }
        nav a {
            color: #333;/* white;*/
            text-decoration: none;
            font-size: 16px;
            padding: 5px 15px;
        }
        nav a:hover {
            background-color: #6b3826;
            border-radius: 5px;
        }
        .hero {
            background-color: #f8f5f0;/* brand iaseai  rgb(181, 78, 18);*/
            color:  #333;/* brand iaseai white;*/
            text-align: center;
            padding: 100px 20px;
        }
        .hero h2 {
            font-size: 36px;
            margin: 0 0 20px;
        }
        .content {
            padding: 40px 20px;
        }
        .card {
            background: white;
            border-radius: 12px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
            margin: 40px auto;
            max-width: 900px;
            padding: 30px;
        }
        .card h2, .card h3 {
            font-size: 24px;
            margin-bottom: 20px;
            color: #854c2f;
            text-align: center;
        }
        .card p {
            margin-bottom: 20px;
        }
        .card ul {
            padding-left: 40px;
        }
        .card ul li {
            margin-bottom: 10px;
            list-style-type: disc;
        }
        .reference {
            text-align: center;
            margin: 50px auto;
            padding: 20px;
            background-color: white;
            border-radius: 12px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
            max-width: 800px;
        }
        .reference a {
            color: #854c2f;
            text-decoration: none;
            font-weight: bold;
        }
        .reference a:hover {
            text-decoration: underline;
        }
        footer {
            background-color: #333;
            color: white;
            text-align: center;
            padding: 20px;
            font-size: 14px;
        }
    </style>
</head>
<body>
    <header>
        <h1>Safe & Ethical AI</h1>
        <nav>
            <a href="#de">Statement DE</a>
            <a href="#en">Statement EN</a>
        </nav>
    </header>

    <section class="hero">
        <h2>Die Gew√§hrleistung einer sicheren und ethischen k√ºnstlichen Intelligenz ist eine globale Herausforderung.</h2>
        <h2>Auch Deutschland muss handeln, um sie zu bew√§ltigen.</h2>
        <h2>Darum rufen wir zur Gr√ºndung eines deutsches Chapters der IASEAI auf.</h2>
        <blockquote style="text-align: center; padding: 20px; font-style: italic; color: #333; max-width: 800px; margin: auto;">
            <p>"The development of highly capable AI is likely to be the biggest event in human history. The world must act decisively to ensure it is not the last event in human history. This conference, and the cooperative spirit of the AI Summit series, give me hope; but we must turn hope into action, soon, if there is to be a future we would want our children to live in."</p>
            <p><strong>‚Äì Professor Stuart Russell, IASEAI President and Distinguished Professor of Computer Science at the University of California</strong></p>
        </blockquote>
    </section>

     <section class="content">
        <div class="card" id="contact">
            <div>
                <h2 style="text-align:center">Kontakt aufnehmen</h2>
                <p>Arbeiten Sie an sicherer und ethischer KI in Deutschland oder sind Sie daran interessiert, einen Beitrag dazu zu leisten? Sind Sie ein Forscher oder Vertreter einer akademischen Einrichtung oder der Industrie, eines Startups oder KMUs, einer NGO oder politischen Organisation oder einer staatlichen Einrichtung?</p>
                <p>
                    M√∂chten Sie den <strong>Aufruf zum Handeln</strong> unterst√ºtzen und als Unterzeichner:in aufgef√ºhrt werden?  
                    Dann tragen Sie sich bitte in unser  
                    <a href="https://docs.google.com/forms/d/e/1FAIpQLScGIB1PXGIM9FgrcNWrrdcj-tUUnORwX_LfZ2ZRDUllainuLA/viewform" target="_blank"><strong>Unterzeichnungsformular</strong></a> ein.
                </p>
                
                <p>
                    F√ºr direkte Anfragen oder weitere Informationen k√∂nnen Sie uns auch per E-Mail erreichen:  
                    üì© <a href="mailto:join@iaseai.de"><strong>join@iaseai.de</strong></a>
                </p>
            </div>
        </div>
    </section>
    
    <section class="content">
        <div class="card" id="de">
            <h2 style="text-align:center">Aufruf zum Handeln<br>
                Gr√ºndung einer deutschen Sektion der Gesellschaft f√ºr sichere und ethische KI sowie eines deutschen Instituts f√ºr KI-Sicherheit
            </h2>
            <p>
                Sehr geehrte Kolleginnen und Kollegen,<br>
                Sehr geehrte Entscheidungstr√§gerinnen und Entscheidungstr√§ger,<br>
                Liebe Branchenf√ºhrende, Vertreterinnen und Vertreter der Zivilgesellschaft sowie <br>
              alle, denen eine sichere und ethische K√ºnstliche Intelligenz am Herzen liegt,<br>
            </p>
            <p>
              im Vorfeld des AI Action Summits in Paris hatten wir das Privileg, an der Gr√ºndungskonferenz der
              <strong>Internationalen Gesellschaft f√ºr sichere und ethische K√ºnstliche Intelligenz 
              (International Association for Safe and Ethical AI, IASEAI)</strong> teilzunehmen. 
              Dieses historische, globale Treffen widmete sich den kurz-, mittel- und langfristigen Herausforderungen 
              fortschrittlicher KI sowie der dringenden Notwendigkeit, robuste Sicherheits- und Ethikstandards zu entwickeln. 
              Der dort formulierte internationale <strong>Aufruf zum Handeln</strong> hat uns tief bewegt, inspiriert und motiviert.    
            </p>
            <p>
                Obwohl diese Herausforderungen und Chancen globaler Natur sind, erfordern sie zugleich entschlossene, lokal getriebene Initiativen.            
            </p>
            <p>
              Heute m√∂chten wir daher Stuart Russells Aufruf zum Abschluss der Konferenz aufgreifen und zur 
              <strong>Gr√ºndung einer deutschen Sektion der IASEAI</strong> aufrufen. Deutschland steht an einem 
              <strong>kritischen Scheideweg:</strong> Da sich die KI-Technologie rasant weiterentwickelt, ist es unerl√§sslich, dass wir gemeinsam proaktiv eine Zukunft gestalten, in der KI der Menschheit sicher und ethisch vertretbar dient ‚Äì unabh√§ngig davon, ob wir aus Wissenschaft, Industrie, Regierung oder Zivilgesellschaft kommen.
        </p>
            <p>
              Wir fordern die deutschen Interessengruppen insbesondere dazu auf, die folgende Priorit√§ten in den Blick zu nehmen:

              <h3>
                Zentrale Forderung: Erh√∂hung √∂ffentlicher Investitionen und Einrichtung eines nationalen Instituts f√ºr sichere KI
              </h3>

          <p>              
            Auch wenn derzeit Wahlkampf tobt ‚Äì und gerade deshalb: Wir fordern die k√ºnftige deutsche Regierung bereits jetzt auf, erhebliche √∂ffentliche Investitionen in Forschung und Infrastruktur f√ºr sichere und ethische KI bereitzustellen.

            Insbesondere sollte ein deutsches Institut f√ºr KI-Sicherheit gegr√ºndet werden, das bestehende Expertise und Initiativen b√ºndelt, eine koh√§rente Strategie f√ºr sichere, vertrauensw√ºrdige und ethische KI entwickelt und interdisziplin√§re Forschung f√∂rdert.
          </p>
  <p>
  <strong>Begr√ºndung:</strong>
</p>
  <p>
          In der √∂ffentlichen Diskussion liegt derzeit ein starker Fokus auf der 
    <strong>Entwicklung eigener fortschrittlicher Sprachmodelle</strong> ‚Äì ein verst√§ndlicher Ansatz angesichts des 
    technologischen R√ºckstands und der daraus resultierenden Abh√§ngigkeit 
    Deutschlands von den USA (und bald wohl auch von China). Doch mindestens ebenso dringlich ist es, eine 
    <strong>sichere und nachhaltige Integration bereits existierender KI-Systeme in unsere Gesellschaft</strong> zu erm√∂glichen.
</p>
  <p>
    Die Notwendigkeit eigener KI-Modelle darf nicht davon ablenken, dass gleichzeitig 
    <strong>robuste Methoden und Standards f√ºr vertrauensw√ºrdige, sichere und ethisch akzeptable KI</strong> entwickelt 
    werden m√ºssen ‚Äì sowohl f√ºr die <strong>Entwicklung, den Einsatz als auch die fortlaufende Kontrolle</strong> dieser Systeme, 
    unabh√§ngig von ihrer Herkunft.
Deutschland fehlt bislang eine nachhaltige und koordinierte Strategie in diesem Bereich, obwohl es 
    vielversprechende, aber weitgehend <strong>unkoordinierte Einzelinitiativen</strong> gibt.
</p>
  <p>
    Vor diesem Hintergrund ist es bezeichnend, dass <strong>Frankreich</strong> und <strong>Indien</strong> beim 
    AI Action Summit bereits die <strong>zweite Welle nationaler AI Safety Institute</strong> gestartet haben. 
    Deutschland sollte diesem Beispiel folgen. <strong>Bestehende Initiativen sollten geb√ºndelt und weiterentwickelt</strong> 
    werden, mit dem Ziel, ein <strong>gemeinsames und koordiniertes Vorgehen</strong> in Deutschland zu etablieren, das in der Gr√ºndung eines nationalen Safety Instituts m√ºndet.
</p>
  <p>
    Um effektive <strong>Kontrollmechanismen und fortschrittliche Sicherheitsmethoden</strong> zu etablieren, 
    sind allerdings <strong>erhebliche √∂ffentliche Investitionen in Forschung und Infrastruktur</strong> unerl√§sslich. 
    Dies ist nicht nur eine <strong>Frage der Sicherheit</strong>, sondern auch eine technologische Notwendigkeit, 
    um Deutschland als Innovationsstandort zu st√§rken. Ohne entschlossene Ma√ünahmen droht Deutschland erneut, 
    den Anschluss an die Weltspitze in diesem essenziellen Bereich zu verlieren ‚Äì und damit eine 
    historische Chance zu verpassen, nicht nur durch Regulierung, sondern auch durch strategische 
    technologische Weichenstellungen eine <strong>europ√§ische Vorreiterrolle</strong> in sicherer und ethischer KI einzunehmen.
</p>
    <h3>Die Rolle einer deutschen IASEAI-Sektion </h3>
<p>    Ein <strong>deutsches Institut f√ºr KI-Sicherheit</strong> muss auf mehreren S√§ulen stehen. 
  Es sollte nicht nur als <strong>Schnittstelle f√ºr internationale Zusammenarbeit</strong> mit anderen AI Safety Institutes fungieren, sondern jedenfalls auch:
</p>
  <ul>
    <strong>
  <li>die Entwicklung von Sicherheitsstandards koordinieren,</li>
    <li>unabh√§ngige Infrastruktur und Dienstleistungen bereitstellen,</li>
    <li>Policies und Richtlinien erarbeiten,</li>
    <li>die relevante Forschung in Deutschland b√ºndeln, vertiefen und ausweiten.</li>
    </strong>
</ul>
  <p>
          Dabei reicht es nicht aus, sich ausschlie√ülich auf die 
    Exzellenz der deutschen Informatik zu verlassen. Vielmehr muss <strong>interdisziplin√§re Forschung</strong> gef√∂rdert werden ‚Äì 
    insbesondere durch eine gezielte Einbindung von <strong>Ethik, Sozialwissenschaften und Politikwissenschaften</strong> in die 
    KI-Sicherheitsforschung. Andere L√§nder, insbesondere <strong>angels√§chsische Staaten und Kanada</strong>, sind in diesem Bereich 
    bereits wesentlich weiter.
</p>
  <p>
    Eine <strong>deutsche Sektion der IASEAI</strong> k√∂nnte hier eine zentrale Rolle spielen: 
    Sie k√∂nnte als Plattform dienen, um umfassende Konzepte zu entwickeln, <strong>internationale Erkenntnisse und 
    Best Practices zur sicheren und ethischen KI zu adaptieren</strong> und in 
    <strong>praktische, lokal zugeschnittene L√∂sungen</strong> zu √ºberf√ºhren.
</p>
  <p>
    Durch die Gr√ºndung einer <strong>deutschen Sektion der IASEAI</strong> k√∂nnen wir die globale Vision einer 
    <strong>sicheren und ethischen KI in konkrete nationale Ma√ünahmen √ºbersetzen</strong>. 
    Diese Sektion sollte als <strong>gemeinsames Forum f√ºr Wissenschaft, Industrie, Politik und Zivilgesellschaft</strong> dienen,
    um die Herausforderungen der KI gemeinsam anzugehen und sicherzustellen, 
    dass ihre Entwicklung im <strong>Einklang mit dem Gemeinwohl</strong> steht.
</p>
  <p>
    Wir rufen <strong>akademische Institutionen, in Deutschland t√§tige Wissenschaftlerinnen und Wissenschaftler, 
      deutsche Unternehmen sowie zivilgesellschaftliche Akteure</strong> auf, sich dieser Initiative anzuschlie√üen.

  <p><strong>
    Lassen Sie uns Hoffnung und Anspr√ºche in konkretes Handeln umwandeln ‚Äì f√ºr eine Zukunft, in der KI-Technologien einen positiven Beitrag f√ºr unsere Gesellschaft leisten und dem Gemeinwohl dienen, statt es zu gef√§hrden. 
</strong>
</p>
       
                <div class="signatures" style="text-align: center; padding-top: 20px;">
            <h3>Erstunterzeichner</h3>
            <p style="font-style: italic;">Dr. Kevin Baum, Deutsches Forschungszentrum f√ºr K√ºnstliche Intelligenz</p>
            <p style="font-style: italic;">Prof. Dr. Kristian Kersting, Technische Universit√§t Darmstadt</p>
            <p style="font-style: italic;">Dr. Patrick Schramowski, Deutsches Forschungszentrum f√ºr K√ºnstliche Intelligenz</p>
            <p style="font-style: italic;">Prof. Dr. Sebastian Vollmer, Deutsches Forschungszentrum f√ºr K√ºnstliche Intelligenz</p>
            <p style="font-style: italic;">Prof. Dr. Ingmar Weber, Universit√§t des Saarlandes</p>
            <p style="font-style: italic;">Prof. Dr. Verena Wolf, Deutsches Forschungszentrum f√ºr K√ºnstliche Intelligenz</p>
                    
            <h3>Unterst√ºtzer</h3>
            <p style="font-style: italic;">Dr. Rasmus Adler, Fraunhofer IESE</p>
            <p style="font-style: italic;">Tanja B√§umel, Deutsches Forschungszentrum f√ºr K√ºnstliche Intelligenz</p>
            <p style="font-style: italic;">Felix Friedrich, Technische Universit√§t Darmstadt</p>
            <p style="font-style: italic;">Timo P. Gros, Deutsches Forschungszentrum f√ºr K√ºnstliche Intelligenz</p>
            <p style="font-style: italic;">Torsten Helfer, CISPA Helmholtz Center for Information Security</p>
            <p style="font-style: italic;">JProf. Maximilian Kiener, Technische Universit√§t Hamburg</p>
            <p style="font-style: italic;">Prof. Dr. Markus Langer, Universit√§t Freiburg</p>
            <p style="font-style: italic;">Prof. Dr. Gerard de Melo, Hasso-Plattner-Institut / Universit√§t Potsdam</p>
            <p style="font-style: italic;">Dr. Andr√© Meyer-Vitali, Deutsches Forschungszentrum f√ºr K√ºnstliche Intelligenz</p>
            <p style="font-style: italic;">Dr. Christian M√ºller, Deutsches Forschungszentrum f√ºr K√ºnstliche Intelligenz</p>
            <p style="font-style: italic;">Dr. Christopher Nehring, Cyberintelligence Institute</p>
            <p style="font-style: italic;">Dr. Simon Ostermann, Deutsches Forschungszentrum f√ºr K√ºnstliche Intelligenz</p>   
            <p style="font-style: italic;">Kanak Raj, Thomson Reuters</p>       
            <p style="font-style: italic;">Nadine Schlicker, Institut f√ºr KI in der Medizin, Philipps-Universit√§t Marburg</p>
            <p style="font-style: italic;">Dr. Vera Schmitt, Technische Universit√§t Berlin</p>
            <p style="font-style: italic;">Manuela Schuler, Deutsches Forschungszentrum f√ºr K√ºnstliche Intelligenz</p>        
            <p style="font-style: italic;">Jayanth Siddamsetty, Deutsches Forschungszentrum f√ºr K√ºnstliche Intelligenz</p>
            <p style="font-style: italic;">Andrea Sipka, Deutsches Forschungszentrum f√ºr K√ºnstliche Intelligenz</p>
            <p style="font-style: italic;">Prof. Dr. Philipp Slusallek, Deutsches Forschungszentrum f√ºr K√ºnstliche Intelligenz</p>
            <p style="font-style: italic;">Yoana Tsoneva, Technische Universit√§t Berlin </p>
        </div>
        </div>
    </div>
</section>


    <section class="content">
  <div class="card" id="en">
            <h2 style="text-align:center">Call to Action<br>
                Establishment of a German Chapter of the Association for Safe and Ethical AI and a German Institute for AI Safety
            </h2>
            <p>
                Dear colleagues,<br>
                Dear decision-makers,<br>
                Dear industry leaders, representatives of civil society,<br>
                and everyone committed to safe and ethical artificial intelligence,
            </p>
            <p>
                Ahead of the AI Action Summit in Paris, we had the privilege of participating in the Inaugural Conference of the
                <strong>International Association for Safe and Ethical AI (IASEAI)</strong>.
                This historic, global gathering was dedicated to addressing the short-, medium-, and long-term challenges of advanced AI,
                as well as the urgent need to develop robust safety and ethics standards.
                The international call to action formulated at this event deeply moved, inspired, and motivated us.
            </p>
            <p>
                Although these challenges and opportunities are global in nature, they require decisive, locally driven initiatives.
            </p>
            <p>
                In response to Stuart Russell‚Äôs call at the conclusion of the conference, we propose the establishment of a German chapter of the IASEAI.
                Germany stands at a critical crossroads: As AI technology rapidly advances, it is essential that we proactively shape a future
                in which AI serves humanity safely and ethically‚Äîwhether we come from academia, industry, government, or civil society.
            </p>
            <h3>Key Demand: Increased Public Investment and the Establishment of a National Institute for AI Safety</h3>
            <p>
                Even in the midst of the ongoing election campaign‚Äîand perhaps especially because of it‚Äîwe urge the next German government to
                allocate substantial public investments in research and infrastructure for safe and ethical AI.
            </p>
            <p>
                Most importantly, a German Institute for AI Safety should be established to consolidate existing expertise and initiatives,
                develop a coherent strategy for safe, trustworthy, and ethical AI, and foster interdisciplinary research.
            </p>
            <p><strong>Rationale</strong></p>
            <p>
                Public discourse in Germany currently places strong emphasis on developing domestic advanced language models‚Äîa reasonable
                approach given Germany‚Äôs technological lag and resulting dependence on the United States (and soon, likely China).
                However, just as urgent is the need to establish mechanisms for the safe and sustainable integration of already existing AI systems into our society.
            </p>
            <p>
                The necessity of developing our own AI models must not distract from the simultaneous need to establish robust methods and
                standards for trustworthy, safe, and ethically acceptable AI‚Äîcovering development, deployment, and continuous oversight,
                regardless of their origin.
            </p>
            <h3>The Role of a German IASEAI Chapter</h3>
            <p>
                A German Institute for AI Safety must rest on multiple pillars. In addition to serving as an interface for international
                collaboration with other AI Safety Institutes, it should also:
            </p>
            <ul>
                <li>Coordinate the development of safety standards</li>
                <li>Provide independent infrastructure and services</li>
                <li>Formulate policies and guidelines</li>
                <li>Consolidate, expand, and advance relevant research in Germany</li>
            </ul>
            <p>
                It is not enough to rely solely on Germany‚Äôs strength in computer science. Instead, interdisciplinary research must be promoted,
                particularly through the systematic inclusion of ethics, social sciences, and political science in AI safety research.
                Other countries‚Äîespecially Anglo-Saxon nations and Canada‚Äîhave already made significant progress in this regard.
            </p>
            <p>
                A German chapter of the IASEAI could play a pivotal role in this effort: serving as a platform for developing comprehensive concepts,
                adapting international insights and best practices on safe and ethical AI, and transforming them into practical, locally tailored solutions.
            </p>
            <p>
                By establishing a German chapter of the IASEAI, we can translate the global vision of safe and ethical AI into concrete national action.
                This chapter should serve as a forum for academia, industry, policymakers, and civil society to address AI challenges collectively
                and ensure its development aligns with the common good.
            </p>
            <p>
                We call upon German academic institutions, researchers, companies, and civil society organizations to join this initiative.
            </p>
            <p><strong>
                Let us turn hope and ambition into concrete action‚Äîshaping a future where AI technologies contribute positively to society
                and serve the common good, rather than threatening it.
            </strong></p>
        <div class="signatures" style="text-align: center; padding-top: 20px;">
            <h3>Initial Signatories</h3>
            <p style="font-style: italic;">Dr. Kevin Baum, German Research Center for Artificial Intelligence</p>
            <p style="font-style: italic;">Prof. Kristian Kersting, Technical University of Darmstadt</p>
            <p style="font-style: italic;">Dr. Patrick Schramowski, German Research Center for Artificial Intelligence</p>
            <p style="font-style: italic;">Prof. Sebastian Vollmer, German Research Center for Artificial Intelligence</p>
            <p style="font-style: italic;">Prof. Ingmar Weber, Saarland University</p>
            <p style="font-style: italic;">Prof. Verena Wolf, German Research Center for Artificial Intelligence</p>            
                    
            <h3>Supporters</h3>
            <p style="font-style: italic;">Dr. Rasmus Adler, Fraunhofer IESE</p>
            <p style="font-style: italic;">Tanja B√§umel, German Research Center for Artificial Intelligence</p>
            <p style="font-style: italic;">Felix Friedrich, Technical University of Darmstadt</p>
            <p style="font-style: italic;">Timo P. Gros, German Research Center for Artificial Intelligence</p>
            <p style="font-style: italic;">Torsten Helfer, CISPA Helmholtz Center for Information Security</p>
            <p style="font-style: italic;">JProf. Maximilian Kiener, Hamburg University of Technology</p>
            <p style="font-style: italic;">Prof. Markus Langer, University of Freiburg</p>
            <p style="font-style: italic;">Prof. Dr. Gerard de Melo, Hasso Plattner Institute / University of Potsdam</p>
            <p style="font-style: italic;">Dr. Andr√© Meyer-Vitali, German Research Center for Artificial Intelligence</p>
            <p style="font-style: italic;">Dr. Christian M√ºller, German Research Center for Artificial Intelligence</p>
            <p style="font-style: italic;">Dr. Christopher Nehring, Cyberintelligence Institute</p>
            <p style="font-style: italic;">Dr. Simon Ostermann, German Research Center for Artificial Intelligence</p>
            <p style="font-style: italic;">Kanak Raj, Thomson Reuters</p>       
            <p style="font-style: italic;">Nadine Schlicker, Institute for AI in Medicine, Philipps University Marburg</p>
            <p style="font-style: italic;">Dr. Vera Schmitt, Technische Universit√§t Berlin</p>
            <p style="font-style: italic;">Manuela Schuler, German Research Center for Artificial Intelligence</p>      
            <p style="font-style: italic;">Jayanth Siddamsetty , German Research Center for Artificial Intelligence</p>
            <p style="font-style: italic;">Andrea Sipka, German Research Center for Artificial Intelligence</p>
            <p style="font-style: italic;">Prof. Philipp Slusallek, German Research Center for Artificial Intelligence</p>
            <p style="font-style: italic;">Yoana Tsoneva, Technische Universit√§t Berlin </p>
        </div>
    </div>
  </section>
    
    <section class="reference">
        <h2>Mehr Informationen √ºber IASEAI</h2>
        <p>
            Besuchen Sie die <a href="https://www.iaseai.org/" target="_blank">offizielle Website der IASEAI</a>,
            um mehr √ºber die internationale Organisation f√ºr sichere und ethische KI zu erfahren.
        </p>
        <p>
            Lesen Sie das <a href="https://www.iaseai.org/conference/statement" target="_blank">j√ºngste Statement</a>
            zur globalen Verantwortung in der KI-Entwicklung.
        </p>
    </section>

</body>
</html>
