<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Safe & Ethical AI</title>
    <style>
        body {
            margin: 0;
            font-family: "Georgia", serif;
            color: #333;
            background-color: #f8f5f0;
            line-height: 1.6;
        }
        header {
            background-color: rgb(181, 78, 18);
            color: white;
            padding: 20px;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        header h1 {
            font-size: 28px;
            margin: 0;
        }
        nav {
            display: flex;
            gap: 20px;
        }
        nav a {
            color: white;
            text-decoration: none;
            font-size: 16px;
            padding: 5px 15px;
        }
        nav a:hover {
            background-color: #6b3826;
            border-radius: 5px;
        }
        .hero {
            background-color: rgb(181, 78, 18);
            color: white;
            text-align: center;
            padding: 100px 20px;
        }
        .hero h2 {
            font-size: 36px;
            margin: 0 0 20px;
        }
        .content {
            padding: 40px 20px;
        }
        .card {
            background: white;
            border-radius: 12px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
            margin: 40px auto;
            max-width: 900px;
            padding: 30px;
        }
        .card h2, .card h3 {
            font-size: 24px;
            margin-bottom: 20px;
            color: #854c2f;
            text-align: center;
        }
        .card p {
            margin-bottom: 20px;
        }
        .card ul {
            padding-left: 40px;
        }
        .card ul li {
            margin-bottom: 10px;
            list-style-type: disc;
        }
        .reference {
            text-align: center;
            margin: 50px auto;
            padding: 20px;
            background-color: white;
            border-radius: 12px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
            max-width: 800px;
        }
        .reference a {
            color: #854c2f;
            text-decoration: none;
            font-weight: bold;
        }
        .reference a:hover {
            text-decoration: underline;
        }
        footer {
            background-color: #333;
            color: white;
            text-align: center;
            padding: 20px;
            font-size: 14px;
        }
    </style>
</head>
<body>
    <header>
        <h1>Safe & Ethical AI</h1>
        <nav>
            <a href="#de">Statement DE</a>
            <a href="#en">Statement EN</a>
        </nav>
    </header>

    <section class="hero">
        <h2>Die Gewährleistung einer sicheren und ethischen künstlichen Intelligenz ist eine globale Herausforderung.</h2>
        <h2>Auch Deutschland muss handeln, um sie zu bewältigen.</h2>
        <blockquote style="text-align: center; padding: 20px; font-style: italic; color: white; max-width: 800px; margin: auto;">
            <p>"The development of highly capable AI is likely to be the biggest event in human history. The world must act decisively to ensure it is not the last event in human history. This conference, and the cooperative spirit of the AI Summit series, give me hope; but we must turn hope into action, soon, if there is to be a future we would want our children to live in."</p>
            <p><strong>– Professor Stuart Russell, IASEAI President and Distinguished Professor of Computer Science at the University of California</strong></p>
        </blockquote>
    </section>

     <section class="content">
        <div class="card" id="contact">
            <div>
                <h2 style="text-align:center">Kontakt aufnehmen</h2>
                <p>Arbeiten Sie an sicherer und ethischer KI in Deutschland oder sind Sie daran interessiert, einen Beitrag dazu zu leisten? Sind Sie ein Forscher oder Vertreter einer akademischen Einrichtung oder der Industrie, eines Startups oder KMUs, einer NGO oder politischen Organisation oder einer staatlichen Einrichtung?</p>
                <p>Wenn Sie Teil eines zukünftigen deutschen Chapters der IASEAI sein möchten (siehe <a href="https://www.iaseai.org/" target="_blank">hier</a> für das internationale Pendant), kontaktieren Sie uns bitte.</p>
                <p><strong>Email us at:</strong> <a href="mailto:join@iaseai.de">join@iaseai.de</a></p>
            </div>
        </div>
    </section>
    
    <section class="content">
        <div class="card" id="de">
            <h2 style="text-align:center">Aufruf zum Handeln<br>
                Gründung einer deutschen Sektion der Gesellschaft für sichere und ethische KI sowie eines deutschen Instituts für KI-Sicherheit
            </h2>
            <p>
                Sehr geehrte Kolleginnen und Kollegen,<br>
                Sehr geehrte Entscheidungsträgerinnen und Entscheidungsträger,<br>
                Liebe Branchenführende, Vertreterinnen und Vertreter der Zivilgesellschaft sowie <br>
              alle, denen eine sichere und ethische Künstliche Intelligenz am Herzen liegt,<br>
            </p>
            <p>
              im Vorfeld des AI Action Summits in Paris hatten wir das Privileg, an der Gründungskonferenz der
              <strong>Internationalen Gesellschaft für sichere und ethische Künstliche Intelligenz 
              (International Association for Safe and Ethical AI, IASEAI)</strong> teilzunehmen. 
              Dieses historische, globale Treffen widmete sich den kurz-, mittel- und langfristigen Herausforderungen 
              fortschrittlicher KI sowie der dringenden Notwendigkeit, robuste Sicherheits- und Ethikstandards zu entwickeln. 
              Der dort formulierte internationale <strong>Aufruf zum Handeln</strong> hat uns tief bewegt, inspiriert und motiviert.    
            </p>
            <p>
                Obwohl diese Herausforderungen und Chancen globaler Natur sind, erfordern sie zugleich entschlossene, lokal getriebene Initiativen.            
            </p>
            <p>
              Heute möchten wir daher Stuart Russells Aufruf zum Abschluss der Konferenz aufgreifen und zur 
              <strong>Gründung einer deutschen Sektion der IASEAI</strong> aufrufen. Deutschland steht an einem 
              <strong>kritischen Scheideweg:</strong> Da sich die KI-Technologie rasant weiterentwickelt, ist es unerlässlich, dass wir gemeinsam proaktiv eine Zukunft gestalten, in der KI der Menschheit sicher und ethisch vertretbar dient – unabhängig davon, ob wir aus Wissenschaft, Industrie, Regierung oder Zivilgesellschaft kommen.
        </p>
            <p>
              Wir fordern die deutschen Interessengruppen insbesondere dazu auf, die folgende Prioritäten in den Blick zu nehmen:

              <h3>
                Zentrale Forderung: Erhöhung öffentlicher Investitionen und Einrichtung eines nationalen Instituts für sichere KI
              </h3>

          <p>              
            Auch wenn derzeit Wahlkampf tobt – und gerade deshalb: Wir fordern die künftige deutsche Regierung bereits jetzt auf, erhebliche öffentliche Investitionen in Forschung und Infrastruktur für sichere und ethische KI bereitzustellen.

            Insbesondere sollte ein deutsches Institut für KI-Sicherheit gegründet werden, das bestehende Expertise und Initiativen bündelt, eine kohärente Strategie für sichere, vertrauenswürdige und ethische KI entwickelt und interdisziplinäre Forschung fördert.
          </p>
  <p>
  <strong>Begründung:</strong>
</p>
  <p>
          In der öffentlichen Diskussion liegt derzeit ein starker Fokus auf der 
    <strong>Entwicklung eigener fortschrittlicher Sprachmodelle</strong> – ein verständlicher Ansatz angesichts des 
    technologischen Rückstands und der daraus resultierenden Abhängigkeit 
    Deutschlands von den USA (und bald wohl auch von China). Doch mindestens ebenso dringlich ist es, eine 
    <strong>sichere und nachhaltige Integration bereits existierender KI-Systeme in unsere Gesellschaft</strong> zu ermöglichen.
</p>
  <p>
    Die Notwendigkeit eigener KI-Modelle darf nicht davon ablenken, dass gleichzeitig 
    <strong>robuste Methoden und Standards für vertrauenswürdige, sichere und ethisch akzeptable KI</strong> entwickelt 
    werden müssen – sowohl für die <strong>Entwicklung, den Einsatz als auch die fortlaufende Kontrolle</strong> dieser Systeme, 
    unabhängig von ihrer Herkunft.
Deutschland fehlt bislang eine nachhaltige und koordinierte Strategie in diesem Bereich, obwohl es 
    vielversprechende, aber weitgehend <strong>unkoordinierte Einzelinitiativen</strong> gibt.
</p>
  <p>
    Vor diesem Hintergrund ist es bezeichnend, dass <strong>Frankreich</strong> und <strong>Indien</strong> beim 
    AI Action Summit bereits die <strong>zweite Welle nationaler AI Safety Institute</strong> gestartet haben. 
    Deutschland sollte diesem Beispiel folgen. <strong>Bestehende Initiativen sollten gebündelt und weiterentwickelt</strong> 
    werden, mit dem Ziel, ein <strong>gemeinsames und koordiniertes Vorgehen</strong> in Deutschland zu etablieren, das in der Gründung eines nationalen Safety Instituts mündet.
</p>
  <p>
    Um effektive <strong>Kontrollmechanismen und fortschrittliche Sicherheitsmethoden</strong> zu etablieren, 
    sind allerdings <strong>erhebliche öffentliche Investitionen in Forschung und Infrastruktur</strong> unerlässlich. 
    Dies ist nicht nur eine <strong>Frage der Sicherheit</strong>, sondern auch eine technologische Notwendigkeit, 
    um Deutschland als Innovationsstandort zu stärken. Ohne entschlossene Maßnahmen droht Deutschland erneut, 
    den Anschluss an die Weltspitze in diesem essenziellen Bereich zu verlieren – und damit eine 
    historische Chance zu verpassen, nicht nur durch Regulierung, sondern auch durch strategische 
    technologische Weichenstellungen eine <strong>europäische Vorreiterrolle</strong> in sicherer und ethischer KI einzunehmen.
</p>
    <h3>Die Rolle einer deutschen IASEAI-Sektion </h3>
<p>    Ein <strong>deutsches Institut für KI-Sicherheit</strong> muss auf mehreren Säulen stehen. 
  Es sollte nicht nur als <strong>Schnittstelle für internationale Zusammenarbeit</strong> mit anderen AI Safety Institutes fungieren, sondern jedenfalls auch:
</p>
  <ul>
    <strong>
  <li>die Entwicklung von Sicherheitsstandards koordinieren,</li>
    <li>unabhängige Infrastruktur und Dienstleistungen bereitstellen,</li>
    <li>Policies und Richtlinien erarbeiten,</li>
    <li>die relevante Forschung in Deutschland bündeln, vertiefen und ausweiten.</li>
    </strong>
</ul>
  <p>
          Dabei reicht es nicht aus, sich ausschließlich auf die 
    Exzellenz der deutschen Informatik zu verlassen. Vielmehr muss <strong>interdisziplinäre Forschung</strong> gefördert werden – 
    insbesondere durch eine gezielte Einbindung von <strong>Ethik, Sozialwissenschaften und Politikwissenschaften</strong> in die 
    KI-Sicherheitsforschung. Andere Länder, insbesondere <strong>angelsächsische Staaten und Kanada</strong>, sind in diesem Bereich 
    bereits wesentlich weiter.
</p>
  <p>
    Eine <strong>deutsche Sektion der IASEAI</strong> könnte hier eine zentrale Rolle spielen: 
    Sie könnte als Plattform dienen, um umfassende Konzepte zu entwickeln, <strong>internationale Erkenntnisse und 
    Best Practices zur sicheren und ethischen KI zu adaptieren</strong> und in 
    <strong>praktische, lokal zugeschnittene Lösungen</strong> zu überführen.
</p>
  <p>
    Durch die Gründung einer <strong>deutschen Sektion der IASEAI</strong> können wir die globale Vision einer 
    <strong>sicheren und ethischen KI in konkrete nationale Maßnahmen übersetzen</strong>. 
    Diese Sektion sollte als <strong>gemeinsames Forum für Wissenschaft, Industrie, Politik und Zivilgesellschaft</strong> dienen,
    um die Herausforderungen der KI gemeinsam anzugehen und sicherzustellen, 
    dass ihre Entwicklung im <strong>Einklang mit dem Gemeinwohl</strong> steht.
</p>
  <p>
    Wir rufen <strong>akademische Institutionen, in Deutschland tätige Wissenschaftlerinnen und Wissenschaftler, 
      deutsche Unternehmen sowie zivilgesellschaftliche Akteure</strong> auf, sich dieser Initiative anzuschließen.

  <p><strong>
    Lassen Sie uns Hoffnung und Ansprüche in konkretes Handeln umwandeln – für eine Zukunft, in der KI-Technologien einen positiven Beitrag für unsere Gesellschaft leisten und dem Gemeinwohl dienen, statt es zu gefährden. 
</strong>
</p>
       
                <div class="signatures" style="text-align: center; padding-top: 20px;">
            <h3>Erstunterzeichner</h3>
            <p style="font-style: italic;">Dr. Kevin Baum, Deutsches Forschungszentrum für Künstliche Intelligenz</p>
            <p style="font-style: italic;">Prof. Kristian Kersting, Technische Universität Darmstadt</p>
            <p style="font-style: italic;">Dr. Patrick Schramowski, Deutsches Forschungszentrum für Künstliche Intelligenz</p>
            <p style="font-style: italic;">Prof. Sebastian Vollmer, Deutsches Forschungszentrum für Künstliche Intelligenz</p>
            <p style="font-style: italic;">Prof. Ingmar Weber, Universität des Saarlandes</p>
        </div>
    </div>
</section>


    <section class="content">
  <div class="card" id="en">
            <h2 style="text-align:center">Call to Action<br>
                Establishment of a German Chapter of the Association for Safe and Ethical AI and a German Institute for AI Safety
            </h2>
            <p>
                Dear colleagues,<br>
                Dear decision-makers,<br>
                Dear industry leaders, representatives of civil society,<br>
                and everyone committed to safe and ethical artificial intelligence,
            </p>
            <p>
                Ahead of the AI Action Summit in Paris, we had the privilege of participating in the Inaugural Conference of the
                <strong>International Association for Safe and Ethical AI (IASEAI)</strong>.
                This historic, global gathering was dedicated to addressing the short-, medium-, and long-term challenges of advanced AI,
                as well as the urgent need to develop robust safety and ethics standards.
                The international call to action formulated at this event deeply moved, inspired, and motivated us.
            </p>
            <p>
                Although these challenges and opportunities are global in nature, they require decisive, locally driven initiatives.
            </p>
            <p>
                In response to Stuart Russell’s call at the conclusion of the conference, we propose the establishment of a German chapter of the IASEAI.
                Germany stands at a critical crossroads: As AI technology rapidly advances, it is essential that we proactively shape a future
                in which AI serves humanity safely and ethically—whether we come from academia, industry, government, or civil society.
            </p>
            <h3>Key Demand: Increased Public Investment and the Establishment of a National Institute for AI Safety</h3>
            <p>
                Even in the midst of the ongoing election campaign—and perhaps especially because of it—we urge the next German government to
                allocate substantial public investments in research and infrastructure for safe and ethical AI.
            </p>
            <p>
                Most importantly, a German Institute for AI Safety should be established to consolidate existing expertise and initiatives,
                develop a coherent strategy for safe, trustworthy, and ethical AI, and foster interdisciplinary research.
            </p>
            <p><strong>Rationale</strong></p>
            <p>
                Public discourse in Germany currently places strong emphasis on developing domestic advanced language models—a reasonable
                approach given Germany’s technological lag and resulting dependence on the United States (and soon, likely China).
                However, just as urgent is the need to establish mechanisms for the safe and sustainable integration of already existing AI systems into our society.
            </p>
            <p>
                The necessity of developing our own AI models must not distract from the simultaneous need to establish robust methods and
                standards for trustworthy, safe, and ethically acceptable AI—covering development, deployment, and continuous oversight,
                regardless of their origin.
            </p>
            <h3>The Role of a German IASEAI Chapter</h3>
            <p>
                A German Institute for AI Safety must rest on multiple pillars. In addition to serving as an interface for international
                collaboration with other AI Safety Institutes, it should also:
            </p>
            <ul>
                <li>Coordinate the development of safety standards</li>
                <li>Provide independent infrastructure and services</li>
                <li>Formulate policies and guidelines</li>
                <li>Consolidate, expand, and advance relevant research in Germany</li>
            </ul>
            <p>
                It is not enough to rely solely on Germany’s strength in computer science. Instead, interdisciplinary research must be promoted,
                particularly through the systematic inclusion of ethics, social sciences, and political science in AI safety research.
                Other countries—especially Anglo-Saxon nations and Canada—have already made significant progress in this regard.
            </p>
            <p>
                A German chapter of the IASEAI could play a pivotal role in this effort: serving as a platform for developing comprehensive concepts,
                adapting international insights and best practices on safe and ethical AI, and transforming them into practical, locally tailored solutions.
            </p>
            <p>
                By establishing a German chapter of the IASEAI, we can translate the global vision of safe and ethical AI into concrete national action.
                This chapter should serve as a forum for academia, industry, policymakers, and civil society to address AI challenges collectively
                and ensure its development aligns with the common good.
            </p>
            <p>
                We call upon German academic institutions, researchers, companies, and civil society organizations to join this initiative.
            </p>
            <p><strong>
                Let us turn hope and ambition into concrete action—shaping a future where AI technologies contribute positively to society
                and serve the common good, rather than threatening it.
            </strong></p>
        <div class="signatures" style="text-align: center; padding-top: 20px;">
            <h3>Initial Signatories</h3>
            <p style="font-style: italic;">Dr. Kevin Baum, German Research Center for Artificial Intelligence</p>
            <p style="font-style: italic;">Prof. Kristian Kersting, Technical University of Darmstadt</p>
            <p style="font-style: italic;">Dr. Patrick Schramowski, German Research Center for Artificial Intelligence</p>
            <p style="font-style: italic;">Prof. Sebastian Vollmer, German Research Center for Artificial Intelligence</p>
            <p style="font-style: italic;">Prof. Ingmar Weber, Saarland University</p>
        </div>
    </div>
  </section>
    
    <section class="reference">
        <h2>Mehr Informationen über IASEAI</h2>
        <p>
            Besuchen Sie die <a href="https://www.iaseai.org/" target="_blank">offizielle Website der IASEAI</a>,
            um mehr über die internationale Organisation für sichere und ethische KI zu erfahren.
        </p>
        <p>
            Lesen Sie das <a href="https://www.iaseai.org/conference/statement" target="_blank">jüngste Statement</a>
            zur globalen Verantwortung in der KI-Entwicklung.
        </p>
    </section>
</body>
</html>
